<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-82G1S3103X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-82G1S3103X');
</script>

<!-- begin _includes/seo.html --><title>spark optimizations - Balpreet Singh</title>
<meta name="description" content="optimizations can be at application code level or at cluster level, here we are looking more at cluster level optimizations">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Balpreet Singh">
<meta property="og:title" content="spark optimizations">
<meta property="og:url" content="http://localhost:4000/blog/spark-optimizations/">


  <meta property="og:description" content="optimizations can be at application code level or at cluster level, here we are looking more at cluster level optimizations">







  <meta property="article:published_time" content="2022-03-12T17:00:00+01:00">






<link rel="canonical" href="http://localhost:4000/blog/spark-optimizations/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Balpreet Singh Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Balpreet Singh
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts/">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/bio-photo.jpg" alt="" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>Senior Data Engineer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="https://khuranabal.github.io/" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/balpreet-singh-654705114" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">Linkedin</span></a></li>
          
        
          
            <li><a href="https://github.com/khuranabal?tab=repositories" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="spark optimizations">
    <meta itemprop="description" content="optimizations can be at application code level or at cluster level, here we are looking more at cluster level optimizations">
    <meta itemprop="datePublished" content="2022-03-12T17:00:00+01:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">spark optimizations
</h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>optimizations can be at application code level or at cluster level, here we are looking more at cluster level optimizations</p>

<h3 id="application-code-level">application code level</h3>

<p>few of the things which can be configured/used, when doing application code are:</p>

<ul>
  <li>partitiong</li>
  <li>bucketing</li>
  <li>cache/persist</li>
  <li>avoid/minimize shuffling</li>
  <li>join optimizations</li>
  <li>optimized file format</li>
  <li>using reduceByKey instead of groupByKey</li>
</ul>

<h3 id="cluster-configuration">cluster configuration</h3>

<p>to understand the cluster level configuration, lets say we have 10 node cluster (worker) with 16 core &amp; 64GB ram each.</p>

<ul>
  <li>executor, is a container which holds some core &amp; memory</li>
  <li>one node can have more than one executor</li>
  <li>executor/container/jvm is same in this context</li>
</ul>

<p><strong>thin executor</strong></p>

<ul>
  <li>create more executors with each executor having minimum possible resources</li>
  <li>one core will always be required by node for daemon threads and one gb memory will be required for operating system</li>
  <li>for above example, 15 executors can be created with one core each</li>
</ul>

<p>cons:</p>

<ul>
  <li>we loose on mutithreading as each executor get one core</li>
  <li>for broadcast, n copies need to be done for n executors</li>
</ul>

<p><strong>fat executor</strong></p>

<ul>
  <li>give maximum possible resources</li>
  <li>one core will be always be required by node for daemon threads and one gb memory will be required for operating system</li>
  <li>for above example, all 15 cores in one executor</li>
</ul>

<p>cons:</p>

<ul>
  <li>if executor hold more than 5 core then hdfs throughput suffers</li>
  <li>if executor holds large memory, garbage collection (removing unused objects from memory) takes lot of time</li>
</ul>

<p><strong>balanced approach</strong></p>

<ul>
  <li>for exmple above as mentioned, one core for daemon threads and one gb for operating system. So we left with 15 cores and 63GB ram. We want mutithreading and hdfs through be optimal, hence we can use 5 cores in executor</li>
  <li>we can have 3 executors with 5 cores &amp; 21GB ram</li>
  <li>out of 21GB ram, some of it is part of overhead(off heap memory aka raw memory)</li>
  <li>max of 348MB/7% of executor memory is off heap memory, it is overhead not part of container, so here approx 1.5GB is overhead, hence around 19GB will be avaialble for each executor</li>
  <li>3 executor per node in 10 node cluster we will have 30 executors</li>
  <li>one executor out of 30 will be taken up by yarn, total 29 executor for application</li>
  <li>tasks in executor is equal to number of cores, so 5 tasks can run parallelly in our case in each executor</li>
</ul>

<h4 id="on-heap-memory">on heap memory</h4>

<ul>
  <li>local to the executor</li>
  <li>jvm manages and does the garbage collection</li>
</ul>

<h4 id="off-heap-memory">off heap memory</h4>

<ul>
  <li>used for some optimizations as garbage collection is not required</li>
  <li>but need to do memory management programmatically to use off heap</li>
</ul>

<p><img src="/assets/images/spark/spark-node.png" alt="spark-node" /></p>

<h3 id="understanding-running-on-cluster">understanding running on cluster</h3>

<ul>
  <li>in hadoop setup like cloudera we have edge nodes which we can connect to</li>
  <li>with edge node we can do some interactive querying and if setting is to <code class="language-plaintext highlighter-rouge">local</code> then it will have just one executor acting as driver &amp; executor both</li>
  <li>we can set master <code class="language-plaintext highlighter-rouge">yarn</code> to run it on full cluster</li>
  <li>use <code class="language-plaintext highlighter-rouge">spark-shell</code> to run <code class="language-plaintext highlighter-rouge">scala</code> code</li>
  <li>to run in local mode: <code class="language-plaintext highlighter-rouge">spark-shell --master local[*]</code></li>
  <li>to run on cluster: <code class="language-plaintext highlighter-rouge">spark-shell --master yarn</code></li>
</ul>

<h4 id="ways-to-allocate-resources">ways to allocate resources</h4>

<p><strong>dynamic</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">spark.dynamicAllocation.enabled</code> is set to true, can be checked in environment tab in spark ui</li>
  <li>few more properties it require</li>
  <li>for long running jobs if it has to work on different number of tasks in different stages then dynamic is good</li>
</ul>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#app will start with initial number of executors as per this property</span>
spark.dynamicAllocation.initialExecutors

<span class="c">#app can use maximum number of executors as per this property</span>
spark.dynamicAllocation.maxExecutors

<span class="c">#app can use minimum number of executors as per this property</span>
spark.dynamicAllocation.minExecutors

<span class="c">#app can use free number of executors as per this property</span>
spark.dynamicAllocation.executorIdleTimeout
</code></pre></div></div>

<p><strong>static</strong></p>

<ul>
  <li>to use it need to disable dynamic allocation</li>
  <li>we cannot ask for more memory then set max in resource negotiator (take in consideration off heap as well 7%)</li>
  <li>same for core</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">spark-shell --conf spark.dynamicAllocation.enabled=false --master yarn --num-executors 20 --executor-cores 2 --executor-memory 2G</code></p>

<h4 id="example-application">example application</h4>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">//lets say data(coloun delimited) we have is: state, date</span>
<span class="c1">//lets say size of file is 10GB</span>
<span class="k">val</span> <span class="nv">rdd1</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">rdd2</span> <span class="k">=</span> <span class="nv">rdd1</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">":"</span><span class="o">)(</span><span class="mi">0</span><span class="o">),</span> <span class="nv">x</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">":"</span><span class="o">)(</span><span class="mi">1</span><span class="o">)))</span>
<span class="k">val</span> <span class="nv">rdd3</span> <span class="k">=</span> <span class="nv">rdd2</span><span class="o">.</span><span class="py">groupByKey</span>
<span class="k">val</span> <span class="nv">rdd4</span> <span class="k">=</span> <span class="nv">rdd3</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">_1</span><span class="o">,</span> <span class="nv">x</span><span class="o">.</span><span class="py">_2</span><span class="o">.</span><span class="py">size</span><span class="o">))</span>
<span class="nv">rdd4</span><span class="o">.</span><span class="py">collect</span>
</code></pre></div></div>

<ul>
  <li>whatever memory is set, 300MB goes for some overhead</li>
  <li>remaining is divided in two parts: storage &amp; execution memory- 60 percent of remaining, additional buffer- 40 percent of remaining</li>
  <li>partitions are decided by number of blocks of data, 10GB file will have 10*1024/128 = 80 partitions</li>
  <li>tasks will be equal to number of partitions, per stage it will be 80 tasks</li>
  <li>executors can execute multiple tasks one after other</li>
  <li>multiple executor cannot work on same partition</li>
  <li>if executor has n core then only n task can be performed at a time</li>
  <li>total parrellism = number of executors * number of cores in each executor</li>
  <li>if groupByKey used, shuffle will happen and if we have 2 distinct keys then no matter cluster size it will have to be processed by only 2 executors</li>
  <li>in case above (2 distinct keys) if input file is 10GB then one executor has to process atleast 5GB and at max ~10GB</li>
  <li>and if memory is not enough on executor it will fail with OOM</li>
  <li>salting can be used to solve such issue, so as less cardinality column can have more distinct keys to have filled partitions to run in parallel</li>
</ul>

<h4 id="salting">salting</h4>

<ul>
  <li>above problem where we have only few partitions to process like only 2 partitions then we underutilize cluster, and it will take more time.</li>
  <li>we can increase container size but still only 2 executors will work, so another options is to use salting</li>
  <li>add random number to the key and increase cardinality(distinct keys) to get parellelism</li>
</ul>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">random</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">scala</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">Random</span>
<span class="k">val</span> <span class="nv">start</span> <span class="k">=</span> <span class="mi">1</span>
<span class="k">val</span> <span class="nv">end</span> <span class="k">=</span> <span class="mi">60</span>
<span class="k">val</span> <span class="nv">rdd1</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">rdd2</span> <span class="k">=</span> <span class="nv">rdd1</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">num</span> <span class="k">=</span> <span class="n">start</span> <span class="o">+</span> <span class="nv">random</span><span class="o">.</span><span class="py">nextInt</span><span class="o">(</span> <span class="o">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">)</span>
  <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">":"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">+</span> <span class="n">num</span><span class="o">,</span><span class="nv">x</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">":"</span><span class="o">)(</span><span class="mi">1</span><span class="o">))</span>
  <span class="o">})</span>
<span class="k">val</span> <span class="nv">rdd3</span> <span class="k">=</span> <span class="nv">rdd2</span><span class="o">.</span><span class="py">groupByKey</span>
<span class="k">val</span> <span class="nv">rdd4</span> <span class="k">=</span> <span class="nv">rdd3</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">_1</span> <span class="o">,</span> <span class="nv">x</span><span class="o">.</span><span class="py">_2</span><span class="o">.</span><span class="py">size</span><span class="o">))</span>
<span class="nv">rdd4</span><span class="o">.</span><span class="py">cache</span>
<span class="k">val</span> <span class="nv">rdd5</span> <span class="k">=</span> <span class="nv">rdd4</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">{</span>
  <span class="nf">if</span><span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">_1</span><span class="o">.</span><span class="py">substring</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">4</span><span class="o">)==</span><span class="s">"WARN"</span><span class="o">)</span>
  <span class="o">(</span><span class="s">"WARN"</span><span class="o">,</span><span class="nv">x</span><span class="o">.</span><span class="py">_2</span><span class="o">)</span>
  <span class="nf">else</span>
  <span class="o">(</span><span class="s">"ERROR"</span><span class="o">,</span><span class="nv">x</span><span class="o">.</span><span class="py">_2</span><span class="o">)</span>   
  <span class="o">})</span>
<span class="k">val</span> <span class="nv">rdd6</span> <span class="k">=</span> <span class="nv">rdd5</span><span class="o">.</span><span class="py">reduceByKey</span><span class="o">(</span><span class="k">_</span><span class="o">+</span><span class="k">_</span><span class="o">)</span>
<span class="nv">rdd6</span><span class="o">.</span><span class="py">collect</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div></div>

<h3 id="memory">memory</h3>

<ul>
  <li>execution memory: memory required for computations like shuffle, join, sort, agg</li>
  <li>storage memory: used for cache</li>
  <li>both share common region</li>
  <li>when no execution running then storage can acquire all memory and vice versa</li>
  <li>execution may evict storage if necessary, it happens until some threshold only</li>
  <li>storage cannot evict execution memory</li>
  <li>max of 384MB or 10% (depends on admin previous case above we used 7%) spark executor memory (memory overhead): off heap memory for vm overhead</li>
  <li>execution (shuffle, join, sort, agg) &amp; storage memory (for cache, broadcast)</li>
  <li>user memory (for data structure, safegaud against OOM)</li>
  <li>reserved memory (storage for running executor): 300MB</li>
</ul>

<p><strong>example</strong>: 4GB we assign to executor then</p>

<ul>
  <li>total: 4096MB</li>
  <li>off heap: 10% of 4GB is 409MB, so 4096+409MB should be avaialble to make executor run</li>
  <li>reserved: 300MB</li>
  <li>execution&amp;storage: 60% of (total-reserved) = 3796MB * .6 = 2277MB</li>
  <li>user memory: 40% of (total-reserved) = 3796MB * .4 = 1518MB</li>
  <li>storage memory is around 50% of storage&amp;execution, so we can have around 2277MB * .5 = 1138MB for cache &amp; broadcast</li>
</ul>

<h3 id="important-internals">important internals</h3>

<ul>
  <li>when working with rdd then after shuffle number of partitions remain same but in dataframe/dataset after shuffle it will create default number of partitions (200), which can be changed</li>
  <li>if we use take/collect action then driver should have that much memory to handle data else it will fail with OOM, it can be configured while invoking spark shell via parameter <code class="language-plaintext highlighter-rouge">--driver-memory</code></li>
</ul>

<h4 id="join">join</h4>

<p>we should aim to avoid/less shuffling &amp; increase parallelism to process faster
for joins we can have either:</p>
<ul>
  <li>one large table and other small then should use broadcast for small</li>
  <li>both small table, spark not the way</li>
  <li>both tables large then filter &amp; aggregations of data as much as possible before join</li>
  <li>at max how many parallel task can run = min(number of partitions set, distinct keys, total cores)</li>
  <li>skew partitions, this happens due to less distinct keys then we can solve using salting</li>
  <li>bucketing &amp; sorting on join column on both the tables can make join faster, this is same as SMB (Sort Merge Bucket) join</li>
</ul>

<p><strong>example</strong>:</p>

<p>if we have 250 cores in cluster, default after shuffling 200 partitions will be there, and we have more than 250 partitions to process initially, in this case:</p>

<ul>
  <li>50 cores left will be wasted</li>
  <li>if distinct keys are only 100 then other 150 will be wasted</li>
</ul>

<h4 id="sort-aggregate-vs-hash-aggregate">sort aggregate vs hash aggregate</h4>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">orderDF</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"csv"</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"inferSchema"</span><span class="o">,</span><span class="kc">true</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span><span class="kc">true</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"path"</span><span class="o">,</span><span class="s">"orders.csv"</span><span class="o">).</span><span class="py">load</span>
<span class="nv">orderDF</span><span class="o">.</span><span class="py">createOrReplaceTempView</span><span class="o">(</span><span class="s">"orders"</span><span class="o">)</span>

<span class="c1">//long running</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"select order_customer_id, date_format(order_date, 'MMMM') orderdt,  count(1) cnt,first(date_format(order_date,'M')) monthnum  from orders group by order_customer_id, orderdt order by cast(monthnum as int)"</span><span class="o">).</span><span class="py">show</span>
<span class="c1">//plan, it uses sort aggregate</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"select order_customer_id, date_format(order_date, 'MMMM') orderdt,  count(1) cnt,first(date_format(order_date,'M')) monthnum  from orders group by order_customer_id, orderdt order by cast(monthnum as int)"</span><span class="o">).</span><span class="py">explain</span>

<span class="c1">//optimized query</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"select order_customer_id, date_format(order_date, 'MMMM') orderdt,  count(1) cnt,first(cast(date_format(order_date,'M') as int)) monthnum  from orders group byorder_customer_id, orderdt order by monthnum"</span><span class="o">).</span><span class="py">show</span>
<span class="c1">//plan, it uses hash aggregate</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"select order_customer_id, date_format(order_date, 'MMMM') orderdt,  count(1) cnt,first(cast(date_format(order_date,'M') as int)) monthnum  from orders group byorder_customer_id, orderdt order by monthnum"</span><span class="o">).</span><span class="py">explain</span>
</code></pre></div></div>

<p><strong>sort aggregate</strong></p>

<ul>
  <li>first the data is sorted based on the grouping columns, which takes time</li>
  <li>for sorting complexity will be O(nlogn)</li>
  <li>if data is doubled then time it takes will be more than double</li>
</ul>

<p><strong>hash aggregate</strong></p>

<ul>
  <li>no sorting is required, as same value will be overwritten for the unique key as aggregate <code class="language-plaintext highlighter-rouge">first</code> is used</li>
  <li>additional memory is required to have the hashtable kind of structure</li>
  <li>if distinct keys are not much then should always go for hash aggregates</li>
  <li>complexity will be O(n)</li>
  <li>hash table kind of structure is not a part of container, rather this additional memory is grabbed as part of off heap memory, not the part of your jvm</li>
</ul>

<p><strong>why in query 1 it took sort aggregate</strong></p>

<p>month number is string, which is immutable. when we are using hash aggregate we should have mutable types in the values</p>

<h3 id="catalyst-optimizer">catalyst optimizer</h3>

<ul>
  <li>structured apis (dataframe/dataset/sparksql) performs better than rdds</li>
  <li>optimizes execution plan for structured apis</li>
  <li>rule based optimization</li>
  <li>new optimization rules can be added</li>
</ul>

<p><img src="/assets/images/spark/catalyst-optimizer.png" alt="catalyst-optimizer" /></p>

<p><strong>parsed logical plan</strong></p>

<ul>
  <li>unresolved</li>
  <li>our query is parsed and we get a parsed logical plan</li>
  <li>it checks for any of the syntax errors</li>
</ul>

<p><strong>resolved/analysed logical plan</strong></p>

<ul>
  <li>resolve the table name, column names etc.</li>
  <li>if column name or table name is not available then analysis exception is raised</li>
</ul>

<p><strong>optimized logical plan</strong></p>

<ul>
  <li>catalyst optimizer</li>
  <li>filter push down</li>
  <li>combining of filters</li>
  <li>combining of projections</li>
  <li>many such rules which are already in place</li>
  <li>we can add our own rules in the catalyst optimizer</li>
</ul>

<p><strong>physical plan</strong></p>

<ul>
  <li>creates mutiple physical plans like Sortaggregate, HashAggregate</li>
  <li>select the physical plan which is the most optimized one with minimum cost</li>
  <li>selected physical plan is converted to rdd code</li>
</ul>

<h3 id="connect-external-source">connect external source</h3>

<p>create dataframe by connectin to mysql table, requires jar <code class="language-plaintext highlighter-rouge">mysql-connector-java.jar</code></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-shell <span class="nt">--driver-class-path</span> /usr/share/java/mysql-connector-java.jar
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">connection_url</span> <span class="o">=</span><span class="s">"jdbc:mysql://servername/databasename"</span>
<span class="k">val</span> <span class="nv">mysqlProperty</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">java</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">Properties</span>
<span class="nv">mysqlProperty</span><span class="o">.</span><span class="py">setProperty</span><span class="o">(</span><span class="s">"user"</span><span class="o">,</span><span class="s">"username"</span><span class="o">)</span>
<span class="nv">mysqlProperty</span><span class="o">.</span><span class="py">setProperty</span><span class="o">(</span><span class="s">"password"</span><span class="o">,</span><span class="s">"password"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">orderDF</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">jdbc</span><span class="o">(</span><span class="n">connection_url</span><span class="o">,</span><span class="s">"tablename"</span><span class="o">,</span><span class="n">mysqlProperty</span><span class="o">)</span><span class="nv">orderDF</span><span class="o">.</span><span class="py">show</span><span class="o">()</span>
</code></pre></div></div>

<h3 id="sources">Sources</h3>

<ul>
  <li>https://databricks.com/glossary/catalyst-optimizer</li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#spark" class="page__taxonomy-item" rel="tag">spark</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#blog" class="page__taxonomy-item" rel="tag">blog</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2022-03-12T17:00:00+01:00">March 12, 2022</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/blog/spark-part-II/" class="pagination--pager" title="spark part-II
">Previous</a>
    
    
      <a href="/blog/spark-streaming/" class="pagination--pager" title="spark streaming
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/spark-streaming/" rel="permalink">spark streaming
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
  processing on continous flowing data, example card fraud detection, find something trending
  MapReduce can only work on batch, not streaming data, spark ...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/spark-part-II/" rel="permalink">spark part-II
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">spark core works on rdds (spark 1 style) but we have high level constructs to query/process data easily, its dataframe/datasets

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/hive-basics/" rel="permalink">hive basics
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">it is open source datawarehouse to process structured data on top of hadoop

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/yarn/" rel="permalink">yarn
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Yet Another Resource Negotiator
Lets first go through how things are in hadoop initial version and what the limitations are which is solved by YARN.

</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://www.linkedin.com/in/balpreet-singh-654705114" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> Linkedin</a></li>
        
      
        
          <li><a href="https://github.com/khuranabal?tab=repositories" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Balpreet Singh. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'khuranabal/khuranabal.github.io');
    script.setAttribute('issue-term', 'pathname');
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
